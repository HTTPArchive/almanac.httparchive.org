{% extends "en/2019/base.html" %}

{% block title %}
Methodology | The Web Almanac by HTTP Archive
{% endblock %}

{% block styles %}
{{ super() }}
<link rel="stylesheet" href="/static/css/page.css">
{% endblock %}

{% block main %}
<article id="methodology" class="main">
  <nav class="index">
    <div class="index-box floating-card">
      <h2 class="header">Index</h2>
      <ul>
        <li><a href="#overview">Overview</a></li>
        <li><a href="#dataset">About the dataset</a>
          <ul>
            <li><a href="#websites">Websites</a></li>
            <li><a href="#metrics">Metrics</a></li>
          </ul>
        </li>
        <li><a href="#tools">Tools</a>
          <ul>
            <li><a href="#webpagetest">WebPageTest</a></li>
            <li><a href="#lighthouse">Lighthouse</a></li>
            <li><a href="#wappalyzer">Wappalyzer</a></li>
            <li><a href="#chrome-ux-report">Chrome UX Report</a></li>
            <li><a href="#third-party-web">Third Party Web</a></li>
            <li><a href="#rework-css">Rework CSS</a></li>
          </ul>
        </li>
        <li><a href="#process">Analytical process</a>
          <ul>
            <li><a href="#brainstorming">Brainstorming</a></li>
            <li><a href="#analysis">Analysis</a></li>
            <li><a href="#interpretation">Interpretation</a></li>
          </ul>
        </li>
        <li><a href="#looking-ahead">Looking ahead</a></li>
      </ul>
    </div>
  </nav>

  <section class="content">
    <section class="intro">
      <h1 class="title">Methodology</h1>
      <img class="content-banner" src="/static/images/methodology-banner.png" alt="">
    </section>

    <section>
        <h1 id="overview">Overview</h1>

        <p>
          The Web Almanac is a project organized by <a href="https://httparchive.org">HTTP Archive</a>.
          HTTP Archive was started in 2010 by Steve Souders with the mission to
          track how the web is built. It evaluates the composition of millions
          of web pages on a monthly basis and makes its terabytes of metadata
          available for analysis on <a href="https://httparchive.org/faq#how-do-i-use-bigquery-to-write-custom-queries-over-the-data">BigQuery</a>.
          Learn more <a href="https://httparchive.org/about">about HTTP Archive</a>.
        </p>

        <p>
          The mission of the Web Almanac is to make the data warehouse of
          HTTP Archive even more accessible to the web community by having
          subject matter experts provide contextualized insights. You can think
          of it as an annual repository of knowledge about the state of the web,
          2019 being its first edition.
        </p>

        <p>
          The 2019 edition of the Web Almanac is comprised of four pillars:
          content, experience, publishing, and distribution. Each part of the
          written report represents a pillar and is made up of chapters
          exploring its different aspects. For example, Part II represents the
          user experience and includes the Performance, Security, Accessibility,
          SEO, PWA, and Mobile Web chapters.
        </p>
    </section>

    <section>
        <h1 id="dataset">About the dataset</h1>

        <p>
          The HTTP Archive dataset is continuously updating with new data
          monthly. For the 2019 edition of the Web Almanac, unless otherwise
          noted in the chapter, all metrics were sourced from the July 2019
          crawl. These results are
          <a href="https://github.com/HTTPArchive/httparchive.org/blob/master/docs/gettingstarted_bigquery.md">publicly queryable</a>
          on BigQuery in tables prefixed with <code>2019_07_01</code>.
        </p>

        <p>
          All of the metrics presented in the Web Almanac are publicly
          reproducible using the dataset on BigQuery. You can browse the queries
          used by all chapters in our <a href="https://github.com/HTTPArchive/almanac.httparchive.org/tree/master/sql/2019">GitHub repository</a>.
        </p>

        <p>
          For example, to understand the median number of bytes of JavaScript per desktop and mobile page, see <a href="https://github.com/HTTPArchive/almanac.httparchive.org/blob/master/sql/2019/01_JavaScript/01_01b.sql">01_01b.sql</a>:
        </p>

        <div class="code-block floating-card">
          <pre><code><span class="code-comment">#standardSQL
# 01_01b: Distribution of JS bytes by client</span>
<span class="code-keyword">SELECT</span>
  percentile,
  _TABLE_SUFFIX <span class="code-keyword">AS</span> client,
  <span class="code-function">APPROX_QUANTILES</span>(<span class="code-function">ROUND</span>(bytesJs <span class="code-keyword">/</span> <span class="code-number">1024</span>, <span class="code-number">2</span>), <span class="code-number">1000</span>)[<span class="code-function">OFFSET</span>(percentile <span class="code-keyword">*</span> <span class="code-number">10</span>)] <span class="code-keyword">AS</span> js_kbytes
<span class="code-keyword">FROM</span>
  <span class="code-string">`httparchive.summary_pages.2019_07_01_*`</span>,
  <span class="code-function">UNNEST</span>([<span class="code-number">10</span>, <span class="code-number">25</span>, <span class="code-number">50</span>, <span class="code-number">75</span>, <span class="code-number">90</span>]) <span class="code-keyword">AS</span> percentile
<span class="code-keyword">GROUP BY</span>
  percentile,
  client
<span class="code-keyword">ORDER BY</span>
  percentile,
  client</code></pre>
        </div>

        <p>
          Results for each metric are publicly viewable in chapter-specific spreadsheets, eg <a href="https://docs.google.com/spreadsheets/d/1kBTglETN_V9UjKqK_EFmFjRexJnQOmLLr-I2Tkotvic/edit?usp=sharing">JavaScript results</a>.
        </p>
    </section>

    <section>
        <h2 id="websites">Websites</h2>

        <p>
          There are 5,790,700 websites in the dataset. Among those, 5,297,442
          are mobile websites and 4,371,973 are desktop websites. Most websites
          are included in both the mobile and desktop subsets.
        </p>

        <p>
          HTTP Archive sources the URLs for its websites from the
          <a href="#chrome-ux-report">Chrome UX Report</a>.
          The Chrome UX Report is a public dataset from Google that aggregates
          user experiences across millions of websites actively visited by
          Chrome users. This gives us a list of websites that are up-to-date and
          a reflection of real-world web usage. The Chrome UX Report dataset
          includes a form factor dimension, which we use to get all of the
          websites accessed by desktop or mobile users.
        </p>

        <p>
          The July 2019 HTTP Archive crawl used by the Web Almanac used the most
          recently available Chrome UX Report release, May 2019 (201905), for
          its list of websites. This dataset was released on June 11, 2019 and
          captures websites visited by Chrome users during the month of May.
        </p>

        <p>
          Due to resource limitations, the HTTP Archive can only test one page
          from each website in the Chrome UX report. To reconcile this, only the
          home pages are included. Be aware that this will introduce some bias
          into the results because a home page is not necessarily representative
          of the entire website.
        </p>

        <p>
          HTTP Archive is also considered a lab testing tool, meaning it tests
          websites from a datacenter and does not collect data from real-world
          user experiences. Therefore all website home pages are tested with an
          empty cache in a logged out state.
        </p>
    </section>

    <section>
      <h2 id="metrics">Metrics</h2>

      <p>
        HTTP Archive collects metrics about how the web is built. It includes
        basic metrics like the number of bytes per page, whether the page was
        loaded over HTTPS, and individual request and response headers. The
        majority of these metrics are provided by <a href="#webpagetest">WebPageTest</a>,
        which acts as the test runner for each website.
      </p>

      <p>
        Other testing tools are used to provide more advanced metrics about the
        page. For example, <a href="#lighthouse">Lighthouse</a>
        is used to run audits against the page to analyze its quality in areas
        like accessibility and SEO. The <a href="#tools">Tools</a> section below
        goes into each of these tools in more detail.
      </p>

      <p>
        To work around some of the inherent limitations of a lab dataset, the
        Web Almanac also makes use of the <a href="#chrome-ux-report">Chrome UX Report</a>
        for metrics on user experiences, especially in the area of web
        performance.
      </p>

      <p>
        Some metrics are completely out of reach. For example, we don't
        necessarily have the ability to detect the tools used to build a
        website. If a website is built using create-react-app, we could tell
        that it uses the React framework, but not necessarily that a particular
        build tool is used. Unless these tools leave detectible fingerprints in
        the website's code, we're unable to measure their usage.
      </p>

      <p>
        Other metrics may not necessarily be impossible to measure, but are
        challenging or unreliable. For example, aspects of web design are
        inherently visual and may be difficult to quantify, like whether a page
        has an intrusive modal dialog.
      </p>
    </section>

    <section>
      <h1 id="tools">Tools</h1>

      <p>
        The Web Almanac is made possible with the help of the following open
        source tools.
      </p>
    </section>

    <section>
      <h2 id="webpagetest">WebPageTest</h2>

      <p>
        <a href="https://www.webpagetest.org/">WebPageTest</a> is a prominent
        web performance testing tool and the backbone of HTTP Archive. We use a
        <a href="https://github.com/WPO-Foundation/webpagetest-docs/blob/master/user/Private%20Instances/README.md">private instance</a>
        of WebPageTest with private test agents, which are the actual browsers
        that test each web page. Desktop and mobile websites are tested under
        different configurations:
      </p>

      <table>
        <thead>
          <tr>
              <th>Config</th>
              <th>Desktop</th>
              <th>Mobile</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Device</td>
            <td>Linux VM</td>
            <td>Emulated Moto G4</td>
          </tr>

          <tr>
            <td>User Agent</td>
            <td>
              Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36 PTST/190704.170731
            </td>
            <td>
              Mozilla/5.0 (Linux; Android 6.0.1; Moto G (4) Build/MPJ24.139-64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Mobile Safari/537.36 PTST/190628.140653
            </td>
          </tr>

          <tr>
            <td>Location</td>
            <td>
              Redwood City, California, USA<br>
              The Dalles, Oregon, USA
            </td>
            <td>
              Redwood City, California, USA<br>
              The Dalles, Oregon, USA
            </td>
          </tr>

          <tr>
            <td>Connection</td>
            <td>Cable (5/1 Mbps 28ms RTT)</td>
            <td>3G (1.600/0.768 Mbps 300ms RTT)</td>
          </tr>

          <tr>
            <td>Viewport</td>
            <td>1200 x 1920px</td>
            <td>512 x 360px</td>
          </tr>
        </tbody>
      </table>

      <p>
        Desktop websites are run from within a desktop Chrome environment on a
        Linux VM. The network speed is equivalent to a cable connection.
      </p>

      <p>
        Mobile websites are run from within a mobile Chrome environment on an
        emulated Moto G4 device with a network speed equivalent to a 3G
        connection. Note that the emulated mobile User Agent self-identifies as
        Chrome 65 but is actually Chrome 75 under the hood.
      </p>

      <p>
        There are two locations from which tests are run: California and
        Oregon USA. HTTP Archive maintains its own test agent hardware located
        in the <a href="https://archive.org">Internet Archive</a> datacenter in
        California. Additional test agents in <a href="https://cloud.google.com/compute/docs/regions-zones/#locations">Google Cloud Platform</a>'s
        us-west-1 location in Oregon are added as needed.
      </p>

      <p>
        HTTP Archive's private instance of WebPageTest is kept in sync with the
        latest public version and augmented with <a href="https://github.com/HTTPArchive/legacy.httparchive.org/tree/master/custom_metrics">custom metrics</a>.
        These are snippets of JavaScript that are evaluated on each website at
        the end of the test. The <a href="https://github.com/HTTPArchive/legacy.httparchive.org/blob/master/custom_metrics/almanac.js">almanac.js</a>
        custom metric includes several metrics that were otherwise infeasible to
        calculate, for example those that depend on  DOM state.
      </p>

      <p>
        The results of each test are made available as a <a href="https://en.wikipedia.org/wiki/HAR_(file_format)">HAR file</a>,
        a JSON-formatted archive file containing metadata about the web page.
      </p>
    </section>

    <section>
      <h2 id="lighthouse">Lighthouse</h2>

      <p>
        <a href="https://developers.google.com/web/tools/lighthouse/">Lighthouse</a>
        is an automated website quality assurance tool built by Google. It
        audits web pages to make sure they don't include user experience
        antipatterns like unoptimized images and inaccessible content.
      </p>

      <p>
        HTTP Archive runs the latest version of Lighthouse for all of its mobile
        web pages — desktop pages are not included because of limited resources.
        As of the July 2019 crawl, HTTP Archive used the <a href="https://github.com/GoogleChrome/lighthouse/releases/tag/v5.1.0">5.1.0</a>
        version of Lighthouse.
      </p>

      <p>
        Lighthouse is run as its own distinct test from within <a href="#webpagetest">WebPageTest</a>,
        but it has its own configuration profile:
      </p>

      <table>
        <thead>
          <tr>
            <th>Config</th>
            <th>Value</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>CPU slowdown</td>
            <td>1x*</td>
          </tr>
          <tr>
            <td>Download throughput</td>
            <td>1.475 Mbps</td>
          </tr>
          <tr>
            <td>Upload throughput</td>
            <td>0.675 Mbps</td>
          </tr>
          <tr>
            <td>RTT</td>
            <td>150 ms</td>
          </tr>
        </tbody>
      </table>

      <aside>
        * Note that Lighthouse is normally configured to have a CPU slowdown of
        4x, but due to a <a href="https://github.com/GoogleChrome/lighthouse/issues/9668#issuecomment-535134232">bug</a>
        in WebPageTest, this was 1x at the time of the tests.
      </aside>

      <p>
        For more information about Lighthouse and the audits available in
        HTTP Archive, refer to the <a href="https://developers.google.com/web/tools/lighthouse/">Lighthouse developer documentation</a>.
      </p>
    </section>

    <section>
      <h2 id="wappalyzer">Wappalyzer</h2>

      <p>
        <a href="https://www.wappalyzer.com/">Wappalyzer</a> is a tool for
        detecting technologies used by web pages. There are
        <a href="https://www.wappalyzer.com/technologies">65 categories</a> of
        technologies tested, ranging from JavaScript frameworks, to CMS
        platforms, and even cryptocurrency miners. There are over 1,200
        supported technologies.
      </p>

      <p>
        HTTP Archive runs the latest version of Wappalyzer for all web pages.
        As of July 2019 the Web Almanac used the
        <a href="https://github.com/AliasIO/Wappalyzer/releases/tag/v5.8.3">5.8.3 version</a>
        of Wappalyzer.
      </p>

      <p>
        Wappalyzer powers many chapters that analyze the popularity of developer
        tools like WordPress, Bootstrap, and jQuery. For example, the
        <a href="{{ url_for('chapter', year=year, lang=lang, chapter='ecommerce') }}">Ecommerce</a>
        and <a href="{{ url_for('chapter', year=year, lang=lang, chapter='cms') }}">CMS</a> chapters rely heavily on the respective
        <a href="https://www.wappalyzer.com/categories/ecommerce">Ecommerce</a> and
        <a href="https://www.wappalyzer.com/categories/cms">CMS</a>
        categories of technologies detected by Wappalyzer.
      </p>
    </section>

    <section>
      <h2 id="chrome-ux-report">Chrome UX Report</h2>

      <p>
        The <a href="https://developers.google.com/web/tools/chrome-user-experience-report">Chrome UX Report</a>
        is a public dataset of real-world Chrome user experiences. Experiences
        are grouped by websites' origin, for example
        <code>https://www.example.com</code>. The dataset includes distributions
        of UX metrics like paint, load, interaction, and layout stability. In
        addition to grouping by month, experiences may also be sliced by
        dimensions like country-level geography, form factor (desktop, phone,
        tablet), and effective connection type (4G, 3G, etc).
      </p>

      <p>
        For Web Almanac metrics that reference real-world user experience data
        from the Chrome UX Report, the July 2019 dataset (201907) is used.
      </p>

      <p>
        You can learn more about the dataset in the
        <a href="https://web.dev/chrome-ux-report-bigquery">Using the Chrome UX Report on BigQuery</a>
        guide on <a href="https://web.dev/">web.dev</a>.
      </p>
    </section>

    <section>
      <h2 id="third-party-web">Third Party Web</h2>

      <p>
        <a href="https://www.thirdpartyweb.today/">Third Party Web</a> is a
        research project by
        <a href="{{ url_for('contributors', year=year, lang=lang, _anchor='patrickhulce') }}">Patrick Hulce</a>,
        author of the
        <a href="{{ url_for('chapter', year=year, lang=lang, chapter='third-parties') }}">Third Parties</a>
        chapter, that uses HTTP Archive and Lighthouse data to identify and analyze the impact of third party resources on the web.
      </p>

      <p>
        Domains are considered to be a third party provider if they appear on at
        least 50 unique pages. The project also groups providers by their
        respective services in categories like ads, analytics, and social.
      </p>

      <p>
        Several chapters in the Web Almanac use the domains and categories from
        this dataset to understand the impact of third parties.
      </p>
    </section>

    <section>
      <h1 id="rework-css">Rework CSS</h1>

      <p>
        <a href="https://github.com/reworkcss/css">Rework CSS</a> is a
        JavaScript-based CSS parser. It takes entire stylesheets and produces a
        JSON-encoded object distinguishing each individual style rule, selector,
        directive, and value.
      </p>

      <p>
        This special purpose tool significantly improved the accuracy of many of
        the metrics in the
        <a href="{{ url_for('chapter', year=year, lang=lang, chapter='css') }}">CSS</a>
        chapter. CSS in all external stylesheets and inline style blocks for
        each page were parsed and queried to make the analysis possible. See
        <a href="https://discuss.httparchive.org/t/analyzing-stylesheets-with-a-js-based-parser/1683">this thread</a>
        for more information about how it was integrated with the HTTP Archive
        dataset on BigQuery.
      </p>
    </section>

    <section>
      <h1 id="process">Analytical process</h1>

      <p>
        The Web Almanac took about a year to plan and execute with the
        coordination of dozens of contributors from the web community. This
        section describes why we chose the metrics you see in the Web Almanac,
        how they were queried, and interpreted.
      </p>
    </section>

    <section>
      <h2 id="brainstorming">Brainstorming</h2>

      <p>
        The inception of the Web Almanac started in January 2019 as a
        <a href="https://discuss.httparchive.org/t/planning-the-web-almanac-2019/1553">post on the HTTP Archive forum</a>
        describing the initiative and gathering support. In March 2019 we
        created a <a href="http://bit.ly/web-almanac-brainstorm">public brainstorming doc</a>
        in which anyone in the web community could write-in ideas for chapters
        or metrics. This was a critical step to ensure we were focusing on
        things that matter to the community and have a diverse set of voices
        included in the process.
      </p>

      <p>
        As a result of the brainstorming, 20 chapters were solidified and we
        began <a href="https://github.com/HTTPArchive/almanac.httparchive.org/issues/2">assigning subject matter experts and peer reviewers to each chapter</a>.
        This process had some inherent bias because of the challenge of getting
        volunteers to commit to a project of this scale. Thus, many of the
        contributors are members of the same professional circles. One explicit
        goal for future editions of the Web Almanac is to encourage even more
        inclusion of underrepresented and heterogeneous voices as authors and
        peer reviewers.
      </p>

      <p>
        We spent May through June 2019 pairing people with chapters and getting
        their input to finalize the individual metrics that will make up each
        chapter.
      </p>
    </section>

    <section>
      <h2 id="analysis">Analysis</h2>

      <p>
        In June 2019, with the stable list of metrics and chapters, data
        analysts triaged the metrics for feasibility. In some cases,
        <a href="https://github.com/HTTPArchive/legacy.httparchive.org/blob/master/custom_metrics/almanac.js">custom metrics</a>
        needed to be created to fill gaps in our analytic capabilities.
      </p>

      <p>
        Throughout July 2019, the HTTP Archive data pipeline crawled several million websites, gathering the metadata to be used in the Web Almanac.
      </p>

      <p>
        Starting in August 2019, the data analysts began writing queries to
        extract the results for each metric. In total,
        <strong>431 queries</strong> were written by hand! You can browse all of
        the queries by chapter in the <a href="https://github.com/HTTPArchive/almanac.httparchive.org/tree/master/sql/2019">sql/2019</a>
        directory of the project's GitHub repository.
      </p>
    </section>

    <section>
      <h2 id="interpretation">Interpretation</h2>

      <p>
        Authors worked with analysts to correctly interpret the results and draw
        appropriate conclusions. As authors wrote their respective chapters,
        they drew from these statistics to support their framing of the state of
        the web. Peer reviewers worked with authors to ensure the technical
        correctness of their analysis.
      </p>

      <p>
        To make the results more easily understandable to readers, web
        developers and analysts created data visualizations to embed in the
        chapter. Some visualizations are simplified to make the conclusions
        easier to grasp. For example, rather than showing a full histogram of a
        distribution, only a handful of percentiles are shown. Unless otherwise
        noted, all distributions are summarized using percentiles, especially
        medians (50th percentile), and not averages.
      </p>

      <p>
        Finally, editors revised the chapters to fix simple grammatical errors
        and ensure consistency across the reading experience.
      </p>
    </section>

    <section>
      <h1 id="looking-ahead">Looking ahead</h1>

      <p>
        The 2019 edition of the Web Almanac is the first of what we hope to be
        an annual tradition in the web community of introspection and a
        commitment to positive change. Getting to this point has been a
        monumental effort thanks to many dedicated
        <a href="{{ url_for('contributors', year=year, lang=lang) }}">contributors</a>
        and we hope to leverage as much of this work as possible to make future
        editions even more streamlined.
      </p>

      <p>
        If you're interested in contributing to the 2020 edition of the
        Web Almanac, please fill out our <a href="https://forms.gle/Qyf3q5pKgdH1cBhq5">interest form</a>.
        We'd love to hear your ideas for making this project even better!
      </p>
    </section>
  </section>
</article>
{% endblock %}

{% block scripts %}
{{ super() }}
<script nonce="{{ csp_nonce() }}">

var indexBox = document.querySelector('.index-box');
var indexBoxTitle = document.querySelector('.index-box h2.header-mobile');

indexBoxTitle.addEventListener('click', function(e) {
  indexBox.classList.toggle('show');
});

</script>
{% endblock %}