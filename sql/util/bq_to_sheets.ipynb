{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/HTTPArchive/almanac.httparchive.org/blob/fellow-vicuna/sql/util/bq_to_sheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "U37785Bxt5tE"
      },
      "outputs": [],
      "source": [
        "# @title Configure the chapter\n",
        "year = 2024 #@param {type: \"integer\"}\n",
        "chapter = \"privacy\" #@param {type: \"string\"}\n",
        "\n",
        "# BigQuery\n",
        "GCP_PROJECT = \"httparchive\" #@param {type: \"string\"}\n",
        "\n",
        "# Git\n",
        "branch_name = f\"{chapter.lower()}-sql-{year}\"\n",
        "\n",
        "# SQL folder\n",
        "folder = r'almanac.httparchive.org/sql/{year}/{chapter}/*.sql'.format(\n",
        "    year=year,\n",
        "    chapter=chapter.lower()\n",
        ")\n",
        "\n",
        "# Google Sheets\n",
        "spreadsheet_name = f\"{chapter.capitalize()} (Web Almanac {year})\"\n",
        "\n",
        "# Set to `None` to create new one or an existing spreadsheet URL.\n",
        "existing_spreadsheet_url = 'https://docs.google.com/spreadsheets/d/18r8cT6x9lPdM-rXvXjsqx84W7ZDdTDYGD59xr0UGOwg/edit' #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVkCxlRQH6Yt",
        "outputId": "e0262f6b-6eed-437f-8b47-49cf9eb43273"
      },
      "outputs": [],
      "source": [
        "# @title Download repo\n",
        "!git clone -b $branch_name https://github.com/HTTPArchive/almanac.httparchive.org.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzhgG5xvbQ1E",
        "outputId": "8bf126c7-25a0-4f38-de04-183c75fae548"
      },
      "outputs": [],
      "source": [
        "# @title Update local branch (if new commits)\n",
        "!cd almanac.httparchive.org/ && git checkout $branch_name && git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45dBifFPJAtO",
        "outputId": "98a0f557-778d-4d94-e0ba-ad0f1e9f12a6"
      },
      "outputs": [],
      "source": [
        "# @title Authenticate\n",
        "import google.auth\n",
        "import os\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = GCP_PROJECT\n",
        "auth.authenticate_user()\n",
        "credentials, project = google.auth.default()\n",
        "client = bigquery.Client()\n",
        "gc = gspread.authorize(credentials)\n",
        "\n",
        "try:\n",
        "  ss = gc.open_by_url(existing_spreadsheet_url)\n",
        "  print(f'Using existing spreadsheet: {ss.url}')\n",
        "except:\n",
        "  ss = gc.create(spreadsheet_name)\n",
        "  print(f'Created a new spreadsheet: {spreadsheet_name}: {ss.url}')\n",
        "existing_sheets = [s.title for s in ss.worksheets()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nblNil985Tjt",
        "outputId": "6adb3bf7-78ec-437a-fdcb-e29b88a5f99c"
      },
      "outputs": [],
      "source": [
        "# @title Upload query results\n",
        "import glob\n",
        "import re\n",
        "from tabulate import tabulate\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "include_regexp = '^.+sql$' # @param {type: \"string\"}\n",
        "exclude_regexp = \"^$\" # @param {type: \"string\"}\n",
        "file_match_include = r'{}'.format(include_regexp)\n",
        "file_match_exclude = r'{}'.format(exclude_regexp)\n",
        "\n",
        "overwrite = False # @param {type: \"boolean\"}\n",
        "dry_run = False # @param {type: \"boolean\"}\n",
        "tb_processed_limit = 0 # @param {type: \"number\"}\n",
        "\n",
        "# Print formatted logs\n",
        "queries_processed_log = []\n",
        "def print_logs_table():\n",
        "    table = tabulate(queries_processed_log, headers=['Query name', 'Skip reason', 'Total Tb billed', 'Sheet name'], tablefmt=\"grid\")\n",
        "    clear_output(wait=True)\n",
        "    print(table)\n",
        "\n",
        "# Find matching SQL queries and save results to Google Sheets.\n",
        "for filepath in glob.iglob(folder):\n",
        "    filename = filepath.split('/')[-1]\n",
        "\n",
        "    queries_processed_log.append([filename, 'Processing...', 'Processing...', 'Processing...'])\n",
        "    print_logs_table()\n",
        "    del queries_processed_log[-1]\n",
        "\n",
        "    if re.search(file_match_include, filename) \\\n",
        "    and not re.search(file_match_exclude, filename):\n",
        "\n",
        "        with open(filepath) as f:\n",
        "            query = f.read()\n",
        "\n",
        "        response = client.query(\n",
        "            query,\n",
        "            job_config = bigquery.QueryJobConfig(dry_run = True)\n",
        "        )\n",
        "\n",
        "        tb_processed = response.total_bytes_processed/1024/1024/1024/1024\n",
        "\n",
        "        if dry_run:\n",
        "            queries_processed_log.append([filename, 'Dry run', f'{tb_processed:.3f}', None])\n",
        "            continue\n",
        "\n",
        "        if tb_processed_limit and tb_processed_limit <= tb_processed:\n",
        "            queries_processed_log.append([filename, 'Data Volume', f'{tb_processed:.3f}', None])\n",
        "            continue\n",
        "\n",
        "        sheet_title = re.sub(r'(\\.sql|[^a-zA-Z0-9]+)', ' ', filename).strip().title()\n",
        "        if sheet_title in existing_sheets:\n",
        "            if not overwrite:\n",
        "                queries_processed_log.append([filename, 'No ovrwrite', f'{tb_processed:.3f}', None])\n",
        "                continue\n",
        "\n",
        "            else:\n",
        "                st = ss.worksheet(sheet_title)\n",
        "                ss.del_worksheet(st)\n",
        "\n",
        "        df = client.query(query).to_dataframe()\n",
        "        rows, cols = df.shape\n",
        "\n",
        "        st = ss.add_worksheet(title = sheet_title, rows = rows, cols = cols)\n",
        "        set_with_dataframe(st, df)\n",
        "        queries_processed_log.append([filename, None, f'{tb_processed:.3f}', sheet_title])\n",
        "\n",
        "    else:\n",
        "        queries_processed_log.append([filename, 'Regex match', None, None])\n",
        "\n",
        "    print_logs_table()\n",
        "\n",
        "print_logs_table()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
