{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/HTTPArchive/almanac.httparchive.org/blob/main/sql/util/bq_to_sheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVkCxlRQH6Yt",
    "outputId": "0e907d5e-3824-4b0c-935d-81e629702390"
   },
   "outputs": [],
   "source": [
    "# @title Download repo\n",
    "!git clone https://github.com/HTTPArchive/almanac.httparchive.org.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "U37785Bxt5tE"
   },
   "outputs": [],
   "source": [
    "# @title Configure the chapter to process\n",
    "GCP_PROJECT = 'httparchive' #@param {type: \"string\"}\n",
    "almanac_year = 2024 #@param {type: \"integer\"}\n",
    "chapter_name = 'privacy' #@param {type: \"string\"}\n",
    "spreadsheet_url = 'https://docs.google.com/spreadsheets/d/1Svyw40Th7VbigX6lpR1lb1WXwTUVKZWrK7O2YELrml4/edit' #@param {type: \"string\", placeholder:\"Enter spreadsheet URL\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzhgG5xvbQ1E",
    "outputId": "9cf3ef02-ec76-43ac-cd63-03edf7f2f619"
   },
   "outputs": [],
   "source": [
    "# @title Update chapter branch\n",
    "branch_name = f'{chapter_name.lower()}-sql-{almanac_year}'\n",
    "!cd almanac.httparchive.org/ && git checkout $branch_name && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "45dBifFPJAtO"
   },
   "outputs": [],
   "source": [
    "# @title Authenticate\n",
    "import google.auth\n",
    "import os\n",
    "from google.colab import auth\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = GCP_PROJECT\n",
    "auth.authenticate_user()\n",
    "credentials, project = google.auth.default()\n",
    "client = bigquery.Client()\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "try:\n",
    "    ss = gc.open_by_url(spreadsheet_url)\n",
    "except:\n",
    "    print('Spreadsheet not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "nblNil985Tjt",
    "outputId": "658cf8f9-cee5-44d0-a6cd-abcabd4038e2"
   },
   "outputs": [],
   "source": [
    "# @title Upload query results\n",
    "\n",
    "import glob\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "filename_match = '(number_of_websites_with_related_origin_trials|most_common_cname_domains)\\.sql' # @param {type: \"raw\", placeholder: \"Enter regexp wrapped in quotes\"}\n",
    "filename_match_exclude = '(ads_and_sellers_graph)\\.sql' # @param {type: \"raw\", placeholder: \"Enter regexp wrapped in quotes\"}\n",
    "dry_run = True # @param {type: \"boolean\"}\n",
    "overwrite_sheets = True # @param {type: \"boolean\"}\n",
    "maximum_tb_billed = None # @param {type: \"raw\", placeholder: \"Insert a number or empty to disable\"}\n",
    "\n",
    "filename_include_regexp = r'{}'.format(filename_match)\n",
    "filename_exclude_regexp = r'{}'.format(filename_match_exclude)\n",
    "folder = r'almanac.httparchive.org/sql/{year}/{chapter}/*.sql'.format(\n",
    "    year=almanac_year,\n",
    "    chapter=chapter_name.lower()\n",
    ")\n",
    "existing_sheets = [s.title for s in ss.worksheets()]\n",
    "\n",
    "# Print formatted logs\n",
    "queries_processed_log = []\n",
    "def print_logs_table(log=None, append=True):\n",
    "    if log:\n",
    "        queries_processed_log.append(log)\n",
    "    table = tabulate(queries_processed_log, headers=['Query name', 'TB processed/billed', 'Sheet name', 'Upload skipped reason'], tablefmt=\"grid\")\n",
    "    if not append:\n",
    "        del queries_processed_log[-1]\n",
    "    clear_output(wait=True)\n",
    "    print(table)\n",
    "\n",
    "# Find matching SQL queries and save results to Google Sheets.\n",
    "for filepath in sorted(glob.iglob(folder)):\n",
    "    filename = filepath.split('/')[-1]\n",
    "\n",
    "    print_logs_table([filename, 'Processing...', 'Processing...', 'Processing...'], append=False)\n",
    "\n",
    "    if re.search(filename_include_regexp, filename) and not re.search(filename_exclude_regexp, filename):\n",
    "\n",
    "        with open(filepath) as f:\n",
    "            query = f.read()\n",
    "\n",
    "        try:\n",
    "            response = client.query(\n",
    "                query,\n",
    "                job_config = bigquery.QueryJobConfig(dry_run = True)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print_logs_table([filename, None, None, f'Dry run query error:\\n{e}'])\n",
    "            continue\n",
    "\n",
    "        tb_processed = response.total_bytes_processed/1024/1024/1024/1024\n",
    "        sheet_title = re.sub(r'(\\.sql|[^a-zA-Z0-9]+)', ' ', filename).strip().title()\n",
    "\n",
    "        if sheet_title in existing_sheets:\n",
    "            if overwrite_sheets:\n",
    "                st = ss.worksheet(sheet_title)\n",
    "            else:\n",
    "                print_logs_table([filename, f'{tb_processed:.3f}', sheet_title, 'Sheet already exists'])\n",
    "                continue\n",
    "\n",
    "        if dry_run:\n",
    "            print_logs_table([filename, f'{tb_processed:.3f}', sheet_title, 'Dry run'])\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if maximum_tb_billed:\n",
    "                response = client.query(\n",
    "                    query,\n",
    "                    job_config = bigquery.QueryJobConfig(\n",
    "                        maximum_bytes_billed = maximum_tb_billed*1024*1024*1024*1024\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                response = client.query(query)\n",
    "\n",
    "            df = response.to_dataframe()\n",
    "            if ('st' not in locals() or st.title != sheet_title):\n",
    "                st = ss.add_worksheet(sheet_title, rows = 1, cols = 1)\n",
    "            set_with_dataframe(st, df, resize=False)\n",
    "\n",
    "            tb_billed = response.total_bytes_billed/1024/1024/1024/1024\n",
    "            print_logs_table([filename, f'{tb_billed:.3f}', sheet_title, None])\n",
    "\n",
    "        except Exception as e:\n",
    "            print_logs_table([filename, f'{tb_processed:.3f}', None, f'Query error:\\n{e}'])\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print_logs_table([filename, None, None, 'Filename mismatch'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
